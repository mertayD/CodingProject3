% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NNetEarlyStoppingCV.R
\name{LMLogisticLossEarlyStoppingCV}
\alias{LMLogisticLossEarlyStoppingCV}
\title{NNetEarlyStoppingCV}
\usage{
LMLogisticLossEarlyStoppingCV(X.mat, y.vec, fold.vec, max.iterations)
}
\arguments{
\item{X.mat}{numeric input feature matrix [n x p]}

\item{fold.vec}{a vector of fold ids}

\item{max.iterations}{scalar integer, max number of iterations}

\item{Y.vec}{numeric input label vetor [n]}

\item{n.hidden.units}{The number of hidden units, U}
}
\value{
Output: list with named elements:
pred.mat               n_observations x max.iterations matrix of predicted values (real number for regression, probability for binary classification).
V.mat                  final weight matrix (n_features+1 x n.hidden.units). The first row of V.mat should be the intercept terms.
w.vec                  final weight vector (n.hidden.units+1). The first element of w.vec should be the intercept term.
predict(testX.mat)     a function that takes an unscaled test feature matrix and 
                       returns a vector of predictions (real numbers for regression, probabilities for binary classification).
mean.validation.loss   
mean.train.loss.vec    (for plotting train/validation loss curves)
selected.steps
}
\description{
This function uses cross fold validatoion to find the percision of the 
NNetEarlyStoppingCV function
}
\examples{
   library(CodingProject3)

   data(SAheart , package = "ElemStatLearn")
   X.mat<-SAheart [1:50,-9]
   y.vec<-SAheart [1:50, 9]
   max.iterations <- 100
   fold.vec <- sample(rep(1:5, l=nrow(X.mat)))
   
   result <- LMLogisticLossEarlyStoppingCV(X.mat, y.vec, fold.vec, max.iterations)
}
